{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a84e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from skimage import data, io, filters, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean \n",
    "from skimage.measure import block_reduce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361a6e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bed746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e5e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creates a numpy array file for the data with RGB tuples for each pixel. \n",
    "This method is used for Neural Networks where tuples are accepted\n",
    "as possible inputs.\n",
    "\n",
    "Parameters:\n",
    "dimension - an integer representing desired of the image:\n",
    "            dimension x dimension\n",
    "\n",
    "save - a boolean representing whether the arrays should be saved or not\n",
    "Returns:\n",
    "x - an array of all of the data with features of desired dimension\n",
    "y - an array of the outputs\n",
    "\n",
    "\n",
    "'''\n",
    "def dataForNN(dimension, save):\n",
    "    cwd = os.getcwd()\n",
    "    metadata = pd.read_csv(cwd+'/data/HAM10000_metadata.csv')\n",
    "    directory1 = cwd+'/data/HAM10000_images_part_1/'\n",
    "    directory2 = cwd+'/data/HAM10000_images_part_2/'\n",
    "    i=0\n",
    "    y=np.empty((10015,7))\n",
    "    x = np.empty((10015, dimension,dimension,3))\n",
    "    c_type = {\"akiec\":np.array([1,0,0,0,0,0,0]),\n",
    "         \"bcc\":np.array([0,1,0,0,0,0,0]),\n",
    "         \"bkl\":np.array([0,0,1,0,0,0,0]),\n",
    "         \"df\":np.array([0,0,0,1,0,0,0]),\n",
    "         \"mel\":np.array([0,0,0,0,1,0,0]),\n",
    "         \"nv\":np.array([0,0,0,0,0,1,0]),\n",
    "         \"vasc\":np.array([0,0,0,0,0,0,1])}\n",
    "    i=0\n",
    "    for imagename in os.listdir(directory1):\n",
    "        x[i] = resize(mpimg.imread(directory1+imagename), \n",
    "                    output_shape=(dimension,dimension,3), \n",
    "                    preserve_range = True,anti_aliasing=True).astype(int)\n",
    "        y[i] = c_type[metadata.loc[metadata['image_id'] == \n",
    "                    imagename[0:len(imagename)-4]]['dx'].array[0]]\n",
    "        i+=1\n",
    "    for imagename in os.listdir(directory2):\n",
    "        x[i] = resize(mpimg.imread(directory2+imagename),\n",
    "                output_shape=(dimension,dimension,3), preserve_range = True,\n",
    "                anti_aliasing=True).astype(int)\n",
    "        y[i] = c_type[metadata.loc[metadata['image_id'] == \n",
    "                    imagename[0:len(imagename)-4]]['dx'].array[0]]\n",
    "        i+=1\n",
    "    #Will be saved outside any folder\n",
    "    if(save):\n",
    "        np.save(str(dimension)+'_'+str(dimension)+\"_Vector\", x)\n",
    "        np.save('Outputs_Vector', y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16bc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataForNN(224,True)\n",
    "#Will be saved to use in this format as well\n",
    "#x = np.load(\"224_224_Vector.npy\")\n",
    "#y = np.load(\"Outputs_Vector.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653a2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf4c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mobile net requires range of -1 to 1\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41b5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4dbab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aedaf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "prediction_layer = tf.keras.layers.Dense(7, activation='softmax')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fc6d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "p = preprocess_input(inputs)\n",
    "p = base_model(p, training=False)\n",
    "p = global_average_layer(p)\n",
    "p = tf.keras.layers.Dropout(0.2)(p)\n",
    "outputs = prediction_layer(p)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d13e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 1e-3\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26209c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "101/101 [==============================] - 35s 340ms/step - loss: 1.0372 - accuracy: 0.6672 - val_loss: 0.8027 - val_accuracy: 0.7112\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 32s 319ms/step - loss: 0.7748 - accuracy: 0.7274 - val_loss: 0.7157 - val_accuracy: 0.7424\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 33s 328ms/step - loss: 0.7031 - accuracy: 0.7524 - val_loss: 0.6904 - val_accuracy: 0.7492\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 33s 328ms/step - loss: 0.6585 - accuracy: 0.7660 - val_loss: 0.6913 - val_accuracy: 0.7530\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 33s 324ms/step - loss: 0.6290 - accuracy: 0.7738 - val_loss: 0.6582 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_val,y_val), validation_batch_size=128, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2dfd7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 9s - loss: 0.7070 - accuracy: 0.7424 - 9s/epoch - 140ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7070242166519165, 0.7423864006996155]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "616e62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "665fe0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10),\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7cdd8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5e02ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "101/101 [==============================] - 49s 475ms/step - loss: 0.8440 - accuracy: 0.7081 - val_loss: 0.6953 - val_accuracy: 0.7467\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 46s 454ms/step - loss: 0.6242 - accuracy: 0.7706 - val_loss: 0.5982 - val_accuracy: 0.7842\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 46s 452ms/step - loss: 0.5283 - accuracy: 0.8087 - val_loss: 0.5658 - val_accuracy: 0.7941\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 46s 456ms/step - loss: 0.4475 - accuracy: 0.8377 - val_loss: 0.5548 - val_accuracy: 0.8091\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 46s 461ms/step - loss: 0.3565 - accuracy: 0.8727 - val_loss: 0.6147 - val_accuracy: 0.8047\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 47s 464ms/step - loss: 0.2809 - accuracy: 0.8990 - val_loss: 0.5998 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 5\n",
    "total_epochs =  5 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(x_train,y_train,batch_size=64,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=(x_val,y_val), validation_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "936bea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 9s - loss: 0.6618 - accuracy: 0.7494 - 9s/epoch - 137ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6618484258651733, 0.7493759393692017]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16848c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model2 = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model2.trainable=False\n",
    "prediction_layer = tf.keras.layers.Dense(7, activation='softmax')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad6ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "p = preprocess_input(inputs)\n",
    "p = base_model2(p, training=False)\n",
    "p = global_average_layer(p)\n",
    "p = tf.keras.layers.Dropout(0.2)(p)\n",
    "outputs = prediction_layer(p)\n",
    "model2 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1489ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 1e-3\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced5c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 12:49:33.507146: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "101/101 [==============================] - 37s 347ms/step - loss: 0.2466 - accuracy: 0.6216 - val_loss: 0.1791 - val_accuracy: 0.7043\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 34s 334ms/step - loss: 0.1741 - accuracy: 0.7017 - val_loss: 0.1577 - val_accuracy: 0.7143\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 33s 322ms/step - loss: 0.1506 - accuracy: 0.7276 - val_loss: 0.1544 - val_accuracy: 0.7187\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 33s 329ms/step - loss: 0.1401 - accuracy: 0.7443 - val_loss: 0.1566 - val_accuracy: 0.7068\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 33s 324ms/step - loss: 0.1279 - accuracy: 0.7580 - val_loss: 0.1399 - val_accuracy: 0.7374\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_val,y_val), validation_batch_size=128, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55effa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model2.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model2.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18143b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10),\n",
    "              loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0057b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "101/101 [==============================] - 51s 490ms/step - loss: 0.1633 - accuracy: 0.7006 - val_loss: 0.1370 - val_accuracy: 0.7399\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 48s 479ms/step - loss: 0.1248 - accuracy: 0.7638 - val_loss: 0.1275 - val_accuracy: 0.7561\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 48s 481ms/step - loss: 0.1054 - accuracy: 0.8046 - val_loss: 0.1218 - val_accuracy: 0.7686\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 48s 472ms/step - loss: 0.0906 - accuracy: 0.8318 - val_loss: 0.1317 - val_accuracy: 0.7467\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 48s 472ms/step - loss: 0.0778 - accuracy: 0.8510 - val_loss: 0.1308 - val_accuracy: 0.7860\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 47s 466ms/step - loss: 0.0682 - accuracy: 0.8664 - val_loss: 0.1272 - val_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 5\n",
    "total_epochs =  5 + fine_tune_epochs\n",
    "\n",
    "history2_fine = model2.fit(x_train,y_train,batch_size=64,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history2.epoch[-1],\n",
    "                         validation_data=(x_val,y_val), validation_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f45fe739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "101/101 [==============================] - 49s 478ms/step - loss: 0.0670 - accuracy: 0.8728 - val_loss: 0.1059 - val_accuracy: 0.8147\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 46s 452ms/step - loss: 0.0581 - accuracy: 0.8911 - val_loss: 0.1002 - val_accuracy: 0.8172\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 46s 451ms/step - loss: 0.0533 - accuracy: 0.8981 - val_loss: 0.1210 - val_accuracy: 0.8203\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 45s 449ms/step - loss: 0.0390 - accuracy: 0.9271 - val_loss: 0.1094 - val_accuracy: 0.8322\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 46s 458ms/step - loss: 0.0349 - accuracy: 0.9396 - val_loss: 0.1158 - val_accuracy: 0.8334\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 45s 446ms/step - loss: 0.0268 - accuracy: 0.9552 - val_loss: 0.2451 - val_accuracy: 0.7948\n"
     ]
    }
   ],
   "source": [
    "fine_tune2_epochs = 5\n",
    "total2_epochs=5+total_epochs\n",
    "history2_fine2 = model2.fit(x_train,y_train,batch_size=64,\n",
    "                         epochs=total2_epochs,\n",
    "                         initial_epoch=history2_fine.epoch[-1],\n",
    "                         validation_data=(x_val,y_val), validation_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9561df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 9s 144ms/step - loss: 0.1159 - accuracy: 0.7793\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7dfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888b11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
